{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from comet_ml import Experiment\n",
    "\n",
    "experiment = Experiment(api_key=\"6tGmiuOfY08czs2b4SHaHI2hw\",\n",
    "                        project_name=\"multi-campaigns\", workspace=\"vprzybylo\")\n",
    "experiment.log_code('/data/data/notebooks/Pytorch_mult_campaigns.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import copy\n",
    "import datetime\n",
    "import itertools\n",
    "from natsort import natsorted\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import csv\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Sampler\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler, Adam\n",
    "from torchvision.utils import save_image\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "from pathlib import Path\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_params = {'axes.labelsize': 'xx-large',\n",
    "         'axes.titlesize':'xx-large',\n",
    "         'xtick.labelsize':'x-large',\n",
    "         'ytick.labelsize':'xx-large'}\n",
    "plt.rcParams.update(plt_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageFolderWithPaths(datasets.ImageFolder):\n",
    "    \"\"\"Custom dataset that includes image file paths. Extends\n",
    "    torchvision.datasets.ImageFolder\n",
    "    \"\"\"\n",
    "\n",
    "    # override the __getitem__ method. this is the method that dataloader calls\n",
    "    def __getitem__(self, index):\n",
    "        # this is what ImageFolder normally returns \n",
    "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
    "        # the image file path\n",
    "        path = self.imgs[index][0]\n",
    "        # make a new tuple that includes original and the path\n",
    "        tuple_with_path = (original_tuple + (path,))\n",
    "        return tuple_with_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### equal pull from classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_weights_for_balanced_classes(train_imgs, nclasses):\n",
    "    #only weight the training dataset \n",
    "\n",
    "    class_sample_counts = [0] * nclasses\n",
    "    for item in train_imgs:  \n",
    "        class_sample_counts[item[1]] += 1\n",
    "    print('counts per class: ', class_sample_counts)\n",
    "\n",
    "#     weight_per_class = [0.] * nclasses\n",
    "#     N = float(sum(class_sample_counts))\n",
    "#     for i in range(nclasses): \n",
    "#         weight_per_class[i] = N/float(class_sample_counts[i])\n",
    "#     weight = [0] * len(images)\n",
    "#     for idx, val in enumerate(images):\n",
    "#         weight[idx] = weight_per_class[val[1]]\n",
    "\n",
    "    class_weights = 1./torch.Tensor(class_sample_counts)\n",
    "    train_targets = [sample[1] for sample in train_imgs]\n",
    "    train_samples_weights = [class_weights[class_id] for class_id in train_targets]\n",
    "\n",
    "    return class_sample_counts, torch.DoubleTensor(train_samples_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_histogram_classcounts(class_names, class_counts):\n",
    "    fig, ax = plt.subplots(figsize=(9,5))\n",
    "\n",
    "    width = 0.75 # the width of the bars \n",
    "    ind = np.arange(len(class_counts))  # the x locations for the groups\n",
    "    ax.barh(class_names, class_counts, width, color=\"blue\", align='center', tick_label=class_names)\n",
    "    #ax.set_yticks(ind+width/2)\n",
    "    #plt.xticks(rotation=-90, ha='center')\n",
    "\n",
    "    for i, v in enumerate(class_counts):\n",
    "        ax.text(v, i-.1, str(v), color='blue')\n",
    "    ax.set_xlabel(\"Count\")\n",
    "    #ax.set_xlim(0,2500)\n",
    "    plt.savefig('../plots/class_counts.png', format='png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_split_train_val(train_data, val_data, class_names, datadir, batch_size, show_sample=True, num_workers=32, valid_size = .8):\n",
    "    \n",
    "    num_classes=len(class_names)\n",
    "    # For an unbalanced dataset we create a weighted sampler              \n",
    "    class_counts, train_samples_weights = make_weights_for_balanced_classes(train_data.dataset.imgs, len(range(num_classes)))                                                                   \n",
    "    make_histogram_classcounts(class_names, class_counts)\n",
    "\n",
    "    train_sampler = torch.utils.data.sampler.WeightedRandomSampler(train_samples_weights, \n",
    "                                                                   len(train_samples_weights),\n",
    "                                                                   replacement=True)                     \n",
    "    trainloader = torch.utils.data.DataLoader(train_data.dataset, batch_size=batch_size,                         \n",
    "                                            sampler = train_sampler, num_workers=num_workers, pin_memory=True)    \n",
    "    \n",
    "    val_sampler = SubsetRandomSampler(val_data.indices)                 \n",
    "    valloader = torch.utils.data.DataLoader(val_data.dataset, batch_size=batch_size,                             \n",
    "                                            sampler = val_sampler, num_workers=num_workers, pin_memory=True)  \n",
    "\n",
    "#     val_samples_weights = make_weights_for_balanced_classes(val_data.dataset.imgs, len(range(num_classes)))                                                                   \n",
    "    \n",
    "#     val_sampler = torch.utils.data.sampler.WeightedRandomSampler(val_samples_weights, \n",
    "#                                                                    len(val_samples_weights),\n",
    "#                                                                    replacement=True)                   \n",
    "#     valloader = torch.utils.data.DataLoader(val_data.dataset, batch_size=batch_size,                 \n",
    "#                                             sampler = val_sampler, num_workers=num_workers, pin_memory=True)    \n",
    "\n",
    "    if show_sample:\n",
    "        show_sample(train_data, train_sampler)\n",
    "\n",
    "    return trainloader, valloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_sample(train_data, train_sampler):\n",
    "\n",
    "    batch_size_sampler=20\n",
    "    sample_loader = torch.utils.data.DataLoader(train_data.dataset, batch_size=batch_size_sampler, \\\n",
    "                                                sampler = train_sampler, num_workers=1, drop_last=True)\n",
    "    data_iter = iter(sample_loader)\n",
    "\n",
    "    images, labels, paths = data_iter.next()\n",
    "    fig, ax = plt.subplots(batch_size_sampler//5, 5, figsize=(10, 8))\n",
    "\n",
    "    for j in range(images.size()[0]):\n",
    "\n",
    "        # Undo preprocessing\n",
    "        image = images[j].permute(1, 2, 0).cpu().numpy()\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "        image = std * image + mean\n",
    "\n",
    "        # Image needs to be clipped between 0 and 1 or it looks like noise when displayed\n",
    "        image = np.clip(image, 0, 1)\n",
    "        ax = ax.flatten()\n",
    "        ax[j].set_title(str(class_names[labels[j]]))\n",
    "        ax[j].axis('off')\n",
    "        ax[j].imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_loader(datadir,\n",
    "                    batch_size,\n",
    "                    num_workers,\n",
    "                    shuffle=True,\n",
    "                    pin_memory=True):\n",
    "    \"\"\"\n",
    "    Utility function for loading and returning a multi-process\n",
    "    test iterator \n",
    "    If using CUDA, num_workers should be set to 1 and pin_memory to True.\n",
    "    Params\n",
    "    ------\n",
    "    - data_dir: path directory to the dataset.\n",
    "    - batch_size: how many samples per batch to load.\n",
    "    - shuffle: whether to shuffle the dataset after every epoch.\n",
    "    - num_workers: number of subprocesses to use when loading the dataset.\n",
    "    - pin_memory: whether to copy tensors into CUDA pinned memory. Set it to\n",
    "      True if using GPU.\n",
    "    Returns\n",
    "    -------\n",
    "    - data_loader: test set iterator.\n",
    "    \"\"\"\n",
    "    transforms_ = transforms.Compose([transforms.Resize((224,224)),  #resizing helps memory usage\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "    all_data_wpath = ImageFolderWithPaths(datadir,transform=transforms_)\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(all_data_wpath,pin_memory=True,shuffle=shuffle,\n",
    "                    batch_size=batch_size, num_workers=num_workers)  \n",
    "\n",
    "    return testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag for feature extracting. When False, we finetune the whole model,\n",
    "#   when True we only update the reshaped layer params\n",
    "def set_parameter_requires_grad(model, feature_extract):\n",
    "    if feature_extract:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract=False, use_pretrained=False):\n",
    "    #all input size of 224\n",
    "    if model_name == \"resnet18\":\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    elif model_name == \"resnet34\":\n",
    "        model_ft = models.resnet34(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    elif model_name == \"resnet152\":\n",
    "        model_ft = models.resnet152(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "\n",
    "    elif model_name == \"vgg16\":\n",
    "        model_ft = models.vgg16_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "\n",
    "    elif model_name == \"vgg19\":\n",
    "        model_ft = models.vgg19_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "\n",
    "    elif model_name == \"squeezenet\":\n",
    "        model_ft = models.squeezenet1_1(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(7,7), stride=(2,2))\n",
    "        #model_ft.num_classes = num_classes\n",
    "\n",
    "    elif model_name == \"densenet169\":\n",
    "        model_ft = models.densenet169(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    elif model_name == \"densenet201\":\n",
    "        model_ft = models.densenet201(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    elif model_name == \"efficient\":\n",
    "        #torch.hub.list('rwightman/gen-efficientnet-pytorch')\n",
    "        #model_ft = torch.hub.load('rwightman/gen-efficientnet-pytorch', 'efficientnet_b0', pretrained=False)\n",
    "        model_ft = EfficientNet.from_name('efficientnet-b0')\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "\n",
    "    return model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_dropout(model, drop_rate=0.1):\n",
    "    for name, child in model.named_children():\n",
    "        if isinstance(child, torch.nn.Dropout):\n",
    "            child.p = drop_rate\n",
    "        set_dropout(child, drop_rate=drop_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, kfold, model_name, model_savename, acc_savename_train, acc_savename_val,\\\n",
    "                save_acc, save_model, dataloaders_dict, epochs, num_classes, feature_extract=False):\n",
    "    #feature extract False for all layers to be updated\n",
    "\n",
    "    set_dropout(model, drop_rate=0.0)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # Send the model to GPU\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        model = nn.DataParallel(model)\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Gather the parameters to be optimized/updated in this run. If we are\n",
    "    #  finetuning we will be updating all parameters. However, if we are\n",
    "    #  doing feature extract method, we will only update the parameters\n",
    "    #  that we have just initialized, i.e. the parameters with requires_grad\n",
    "    #  is True.\n",
    "    params_to_update = model.parameters()\n",
    "    #print(\"Params to learn:\")\n",
    "    if feature_extract:\n",
    "        params_to_update = []\n",
    "\n",
    "        for name,param in model.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                params_to_update.append(param)\n",
    "                #print(\"\\t\",name)\n",
    "    #else:\n",
    "        #for name,param in model.named_parameters():\n",
    "            #if param.requires_grad == True:\n",
    "                #print(\"\\t\",name)\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, nesterov=True)\n",
    "    # step_size: at how many multiples of epoch you decay\n",
    "    # step_size = 1, after every 1 epoch, new_lr = lr*gamma \n",
    "    # step_size = 2, after every 2 epoch, new_lr = lr*gamma \n",
    "    # gamma = decaying factor\n",
    "    #scheduler = StepLR(optimizer, step_size=1, gamma=0.1)\n",
    "\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=0, verbose=True, eps=1e-04)\n",
    "\n",
    "    # Setup the loss fxn\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    val_acc_history = []\n",
    "    train_acc_history = []\n",
    "    val_loss_history = []\n",
    "    train_loss_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc_val = 0.0\n",
    "    since_total = time.time()\n",
    "\n",
    "    step = 0\n",
    "    label_counts = [0]*len(range(num_classes))\n",
    "    for epoch in range(epochs):\n",
    "        since_epoch = time.time()\n",
    "        #print('Epoch {}/{}'.format(epoch+1,num_epochs))\n",
    "        print('-' * 20)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            print('Phase: {}'.format(phase))\n",
    "            totals_train = 0\n",
    "            totals_val = 0\n",
    "            running_loss_train = 0.0\n",
    "            running_loss_val = 0.0\n",
    "            running_corrects_train = 0\n",
    "            running_corrects_val = 0\n",
    "\n",
    "            if phase == 'train':\n",
    "                model.train() \n",
    "                #logger = logger_train\n",
    "\n",
    "            else:\n",
    "                model.eval()   \n",
    "                #logger = logger_val\n",
    "\n",
    "            # Iterate over data.\n",
    "            for i, (inputs, labels, paths) in enumerate(dataloaders_dict[phase]):\n",
    "                for n in range(len(range(num_classes))):\n",
    "                    label_counts[n] += len(np.where(labels.numpy() == n)[0])\n",
    "\n",
    "#                 for n in range(len(range(num_classes))):\n",
    "#                     print(\"batch index {}, {} counts: {}\".format(\n",
    "#                         i, n, (labels == n).sum()))\n",
    "\n",
    "\n",
    "#                print('LABEL COUNT = ', label_counts)\n",
    "\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                #print(inputs.device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad() # a clean up step for PyTorch\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward() # compute updates for each parameter\n",
    "                        optimizer.step() # make the updates for each parameter \n",
    "\n",
    "                if phase == 'train':\n",
    "                    #Batch accuracy and loss statistics   \n",
    "                    batch_loss_train = loss.item() * inputs.size(0)     \n",
    "                    batch_corrects_train = torch.sum(preds == labels.data) \n",
    "                    #tensorboard_logging(logger, batch_loss_train, labels, batch_corrects_train, step, model)\n",
    "\n",
    "                    #for accuracy and loss statistics overall \n",
    "                    running_loss_train += loss.item() * inputs.size(0)\n",
    "                    running_corrects_train += torch.sum(preds == labels.data)\n",
    "                    totals_train += labels.size(0)\n",
    "\n",
    "                    if (i+1) % 5 == 0:\n",
    "                        print(\"Training, Batch {}/{}, Loss: {:.3f}, Accuracy: {:.3f}\".format(i+1,\\\n",
    "                                                                      len(dataloaders_dict[phase]), \\\n",
    "                                                                      batch_loss_train/labels.size(0), \\\n",
    "                                                                      float(batch_corrects_train)/labels.size(0)))\n",
    "                    step += 1\n",
    "\n",
    "                else:\n",
    "                    #Batch accuracy and loss statistics  \n",
    "                    batch_loss_val = loss.item() * inputs.size(0)     \n",
    "                    batch_corrects_val = torch.sum(preds == labels.data) \n",
    "\n",
    "                    #for accuracy and loss statistics overall\n",
    "                    running_loss_val += loss.item() * inputs.size(0)\n",
    "                    running_corrects_val += torch.sum(preds == labels.data)\n",
    "                    totals_val += labels.size(0)\n",
    "\n",
    "                    if (i+1) % 3 == 0:\n",
    "                        print(\"Validation, Batch {}/{}, Loss: {:.3f}, Accuracy: {:.3f}\".format(i+1,\\\n",
    "                                                                      len(dataloaders_dict[phase]), \\\n",
    "                                                                      batch_loss_val/labels.size(0), \\\n",
    "                                                                      float(batch_corrects_val)/labels.size(0)))\n",
    "            if phase == 'train':\n",
    "                #epoch loss and accuracy stats    \n",
    "                epoch_loss_train = running_loss_train / totals_train\n",
    "                epoch_acc_train = running_corrects_train.double() / totals_train\n",
    "                scheduler.step(epoch_acc_train) #reduce learning rate if not improving acc\n",
    "                #experiment.log_metric('train scheduler', scheduler)\n",
    "\n",
    "                #write acc and loss to file within epoch iteration\n",
    "                if save_acc:\n",
    "                    with open(acc_savename_train, 'a', newline='') as file:\n",
    "                        writer = csv.writer(file)\n",
    "                        writer.writerow([model_name, epoch, kfold, epoch_acc_train.cpu().numpy(), epoch_loss_train])\n",
    "                    file.close()\n",
    "\n",
    "                print(\"Training Epoch {}/{}, Loss: {:.3f}, Accuracy: \\033[1m {:.3f} \\033[0m\".format(epoch+1,epochs, epoch_loss_train, epoch_acc_train))\n",
    "                train_acc_history.append(epoch_acc_train)\n",
    "                train_loss_history.append(epoch_loss_train)\n",
    "                #experiment.log_metric('epoch_acc_train', epoch_acc_train*100)\n",
    "                #experiment.log_metric('epoch_loss_train', epoch_loss_train)\n",
    "\n",
    "            else: \n",
    "                epoch_loss_val = running_loss_val / totals_val\n",
    "                epoch_acc_val = running_corrects_val.double() / totals_val\n",
    "                scheduler.step(epoch_acc_val) #reduce learning rate if not improving acc\n",
    "                #experiment.log_metric('val scheduler', scheduler)\n",
    "\n",
    "                #write acc and loss to file within epoch iteration\n",
    "                if save_acc:\n",
    "                    with open(acc_savename_val, 'a', newline='') as file:\n",
    "                        writer = csv.writer(file)\n",
    "                        writer.writerow([model_name, epoch, kfold, epoch_acc_val.cpu().numpy(), epoch_loss_val])\n",
    "                    file.close()\n",
    "\n",
    "                print(\"Validation Epoch {}/{}, Loss: {:.3f}, Accuracy: \\033[1m {:.3f} \\033[0m\".format(epoch+1,epochs, epoch_loss_val, epoch_acc_val))\n",
    "                val_acc_history.append(epoch_acc_val)\n",
    "                val_loss_history.append(epoch_loss_val)\n",
    "                #experiment.log_metric('epoch_acc_val', epoch_acc_val*100)\n",
    "                #experiment.log_metric('epoch_loss_val', epoch_loss_val)\n",
    "\n",
    "                #deep copy the model\n",
    "                if epoch_acc_val > best_acc_val:\n",
    "                    best_acc_val = epoch_acc_val\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                    #save/load best model weights\n",
    "                    if save_model:\n",
    "                        torch.save(model, model_savename+'_'+model_name)\n",
    "\n",
    "        time_elapsed = time.time() - since_epoch\n",
    "        print('Epoch complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "    time_elapsed = time.time() - since_total\n",
    "    print('All epochs comlete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "    #with open('/data/data/saved_models/model_timing.csv', 'a', newline='') as file:\n",
    "    #    writer = csv.writer(file)\n",
    "    #    writer.writerow([model_name, epoch, kfold, time_elapsed])\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    all_transforms = transforms.Compose([transforms.Resize(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "    #custom dataset that includes entire path\n",
    "    all_data_wpath = ImageFolderWithPaths(params['data_dir'],transform=all_transforms) \n",
    "\n",
    "    for batch_size in params['batch_size']:\n",
    "        print('BATCH SIZE: ', batch_size) \n",
    "        for model_name in params['model_names']: \n",
    "            print('MODEL: ', model_name)\n",
    "            for epochs in params['max_epochs']:\n",
    "                print('MAX EPOCH: ', epochs)\n",
    "\n",
    "                #K-FOLD \n",
    "                if params['kfold']!=0:\n",
    "                    train_score = pd.Series(dtype=np.float64)\n",
    "                    val_score = pd.Series(dtype=np.float64)\n",
    "\n",
    "                    total_size = len(all_data_wpath)\n",
    "                    fraction = 1/params['kfold']\n",
    "                    seg = int(total_size * fraction)\n",
    "                    # tr:train,val:valid; r:right,l:left;  eg: trrr: right index of right side train subset \n",
    "                    # index: [trll,trlr],[vall,valr],[trrl,trrr]\n",
    "\n",
    "                    for i in range(params['kfold']):\n",
    "                        print('KFOLD: ', i)\n",
    "                        trll = 0\n",
    "                        trlr = i * seg\n",
    "                        vall = trlr\n",
    "                        valr = i * seg + seg\n",
    "                        trrl = valr\n",
    "                        trrr = total_size\n",
    "\n",
    "                        print(\"train indices: [%d,%d),[%d,%d), test indices: [%d,%d)\" \n",
    "                          % (trll,trlr,trrl,trrr,vall,valr))\n",
    "\n",
    "                        train_left_indices = list(range(trll,trlr))\n",
    "                        train_right_indices = list(range(trrl,trrr))\n",
    "\n",
    "                        train_indices = train_left_indices + train_right_indices\n",
    "                        val_indices = list(range(vall,valr))\n",
    "\n",
    "                        train_data = torch.utils.data.dataset.Subset(all_data_wpath, train_indices)\n",
    "                        val_data = torch.utils.data.dataset.Subset(all_data_wpath, val_indices)\n",
    "\n",
    "                        train_loader, val_loader = load_split_train_val(\n",
    "                                train_data,\n",
    "                                val_data,\n",
    "                                class_names=params['class_names'], \n",
    "                                datadir=params['data_dir'],\n",
    "                                batch_size=batch_size,\n",
    "                                show_sample=False,\n",
    "                                num_workers=num_workers)\n",
    "\n",
    "                        dataloaders_dict = {'train': train_loader, 'val': val_loader}\n",
    "\n",
    "                        #INITIALIZE MODEL\n",
    "                        model = initialize_model(model_name, num_classes)\n",
    "\n",
    "                        #TRAIN MODEL\n",
    "                        train_model(model, i, model_name,\n",
    "                                    model_savename,\n",
    "                                    acc_savename_train,\n",
    "                                    acc_savename_val,\n",
    "                                    save_acc,\n",
    "                                    save_model,\n",
    "                                    dataloaders_dict,\n",
    "                                    epochs, \n",
    "                                    num_classes)\n",
    "                else: #no kfold\n",
    "                    i=0\n",
    "                    train_length = int(valid_size*len(all_data_wpath))\n",
    "                    val_length = len(all_data_wpath)-train_length\n",
    "                    train_data, val_data = torch.utils.data.random_split(all_data_wpath,(train_length,val_length))                \n",
    "\n",
    "                    train_loader, val_loader = load_split_train_val(\n",
    "                            train_data,\n",
    "                            val_data,\n",
    "                            class_names=params['class_names'],\n",
    "                            datadir=params['data_dir'],\n",
    "                            batch_size=batch_size,\n",
    "                            show_sample=False,\n",
    "                            num_workers=num_workers)\n",
    "\n",
    "                    dataloaders_dict = {'train': train_loader, 'val': val_loader}\n",
    "\n",
    "                    #INITIALIZE MODEL\n",
    "                    model = initialize_model(model_name, num_classes)\n",
    "\n",
    "                    #TRAIN MODEL\n",
    "                    train_model(model, i, model_name,\n",
    "                                model_savename,\n",
    "                                acc_savename_train,\n",
    "                                acc_savename_val,\n",
    "                                save_acc,\n",
    "                                save_model,\n",
    "                                dataloaders_dict,\n",
    "                                epochs, \n",
    "                                num_classes)\n",
    "                    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    params = {'kfold': 0, #set to 0 to turn off kfold cross validation\n",
    "              'batch_size': [128],\n",
    "              'masked': True,\n",
    "              'max_epochs': [5],\n",
    "              'data_dir': '/data/data/cpi_data/training_datasets/hand_labeled_resized_multcampaigns_clean/',\n",
    "              'class_names': ['aggs','blank','blurry','budding','bullets','columns','compact irregulars',\\\n",
    "                           'fragments','needles','plates','rimed aggs','rimed columns','spheres'],\n",
    "              'model_names': ['efficient', 'resnet18', 'resnet34', 'resnet152', 'alexnet', 'vgg16', 'vgg19', 'densenet169', 'densenet201']}\n",
    "\n",
    "    if params['masked']:\n",
    "        masked_dir='masked/'\n",
    "    else:\n",
    "        masked_dir='no_mask/'\n",
    "        \n",
    "    model_savename ='/data/data/saved_models/'+masked_dir+\\\n",
    "                    'e'+str(params['max_epochs'][0])+\\\n",
    "                    '_bs'+str(params['batch_size'][0])+\\\n",
    "                    '_k'+str(params['kfold'])+'_'+\\\n",
    "                    str(len(params['model_names']))+'models'\n",
    "    acc_savename_train = '/data/data/saved_models/'+masked_dir+\\\n",
    "                    'save_train_acc_loss_e'+\\\n",
    "                    str(params['max_epochs'][0])+\\\n",
    "                    '_bs'+str(params['batch_size'][0])+\\\n",
    "                    '_k'+str(params['kfold'])+'_'+\\\n",
    "                    str(len(params['model_names']))+'models.csv'\n",
    "    acc_savename_val =  '/data/data/saved_models/'+masked_dir+\\\n",
    "                    'save_val_acc_loss_e'+\\\n",
    "                    str(params['max_epochs'][0])+\\\n",
    "                    '_bs'+str(params['batch_size'][0])+\\\n",
    "                    '_k'+str(params['kfold'])+'_'+\\\n",
    "                    str(len(params['model_names']))+'models.csv'\n",
    "    save_acc=True\n",
    "    save_model=True\n",
    "    valid_size=0.8 #80-20 split training-val\n",
    "    num_workers = 20  #change to # of cores available to load images\n",
    "    num_classes = len(params['class_names'])\n",
    "\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ACCURACY PLOT for training and validation\n",
    "fig = plt.figure(figsize=(12,5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(np.arange(1,(params['max_epochs'][0]+1)),[i.cpu().numpy()*100 for i in model_train_accs[0]], label='train')\n",
    "plt.plot(np.arange(1,(params['max_epochs'][0]+1)),[i.cpu().numpy()*100 for i in model_val_accs[0]], label='validation')\n",
    " \n",
    "plt.legend()\n",
    "plt.xticks(np.arange(1, (params['max_epochs'][0]+1), 10.0))\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy [%]\")\n",
    "\n",
    "#LOSS PLOT for training and validation\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(np.arange(1,(params['max_epochs'][0]+1)),[i for i in model_train_loss[0]], label='train')\n",
    "plt.plot(np.arange(1,(params['max_epochs'][0]+1)),[i for i in model_val_loss[0]], label='validation')\n",
    "plt.legend()\n",
    "plt.xticks(np.arange(1, (params['max_epochs'][0]+1), 10.0))\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View Predictions on Validation Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    ''' Scales, crops, and normalizes a PIL image for a PyTorch model,\n",
    "        returns a Numpy array\n",
    "    '''\n",
    "\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    image = preprocess(image)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict2(path, model, topk=9):\n",
    "    ''' Predict the class (or classes) of an image using a trained deep learning model.\n",
    "    '''\n",
    "    img = Image.open(path)\n",
    "    img = img.convert('RGB')\n",
    "    img = process_image(img)\n",
    "    \n",
    "    # Convert 2D image to 1D vector\n",
    "    img = np.expand_dims(img, 0)\n",
    "\n",
    "    img = torch.from_numpy(img)\n",
    "    \n",
    "    model.eval()\n",
    "    inputs = Variable(img).to(device)\n",
    "    logits = model.forward(inputs)\n",
    "    \n",
    "    ps = F.softmax(logits,dim=1)\n",
    "    topk = ps.cpu().topk(topk)\n",
    "    \n",
    "    return (e.data.numpy().squeeze().tolist() for e in topk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_classify(im, prob, crystal_names):\n",
    "    ''' Function for viewing an image and it's predicted classes.\n",
    "    '''\n",
    "    \n",
    "    image = Image.open(im)\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(7, 10), ncols=1, nrows=2)\n",
    "    \n",
    "    ax1.set_title(crystal_names[0])\n",
    "    ax1.imshow(image)\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    y_pos = np.arange(len(prob))\n",
    "    ax2.barh(y_pos, prob, align='center')\n",
    "    ax2.set_yticks(y_pos)\n",
    "    ax2.set_yticklabels(crystal_names)\n",
    "    ax2.tick_params(axis='y', rotation=45)\n",
    "    ax2.invert_yaxis()  # labels read top-to-bottom\n",
    "    ax2.set_title('Class Probability')\n",
    "    plt.show()\n",
    "    #current_time = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    #fig.savefig('classify/'+current_time+'.png',bbox_inches='tight',pad_inches=.3)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('../saved_models/e_50_bs128_k0_1models_efficient').cuda()\n",
    "model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "val_loader = torch.load('../saved_models/val_loader.pth')\n",
    "for batch_idx, (imgs, labels, img_paths) in enumerate(val_loader):\n",
    "    #predictions = model_ft(imgs)\n",
    "    #preds = torch.max(predictions, 1).indices.tolist()    \n",
    "    \n",
    "    for im in img_paths:\n",
    "        probs, classes = predict2(im, model.to(device))  \n",
    "        crystal_names = [params['class_names'][e] for e in classes]\n",
    "        view_classify(im, probs, crystal_names)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(data_dir, save_dir, crystal_names, im):\n",
    "    image = Image.open(data_dir + im).convert(\"RGB\")\n",
    "    if crystal_names[0] == 'rimed aggs':\n",
    "        crystal_names[0] = 'rimed_aggs'\n",
    "    if crystal_names[0] == 'rimed columns':\n",
    "        crystal_names[0] = 'rimed_columns'\n",
    "    if crystal_names[0] == 'compact irregulars':\n",
    "         crystal_names[0] = 'compact_irregulars'\n",
    "    if not os.path.exists(save_dir+crystal_names[0]):\n",
    "        os.makedirs(save_dir+crystal_names[0])\n",
    "    image.save(save_dir+crystal_names[0]+'/'+im) \n",
    "    # cv2.imwrite(save_dir+crystal_names[0]+'/'+im, image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on new data - Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataSet(Dataset):\n",
    "    def __init__(self, main_dir, transform):\n",
    "        self.main_dir = main_dir\n",
    "        self.transform = transform\n",
    "        all_imgs = os.listdir(main_dir)\n",
    "        self.total_imgs = natsorted(all_imgs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.total_imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_loc = os.path.join(self.main_dir, self.total_imgs[idx])\n",
    "        image = Image.open(img_loc)\n",
    "        #print(image)\n",
    "        #image =cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        tensor_image = self.transform(image)\n",
    "        path = self.total_imgs[idx]\n",
    "        return tensor_image, path\n",
    "\n",
    "model = torch.load('../saved_models/bs128_e50_13classes_clean_vgg19').cuda()\n",
    "model.eval()\n",
    "campaign = 'ARM'\n",
    "data_dir = '../cpi_data/campaigns/'+campaign+'/single_imgs/'\n",
    "#save_dir = 'cpi_data/campaigns/'+campaign+'/'\n",
    "\n",
    "#apply same transforms\n",
    "test_transforms = transforms.Compose([transforms.Resize(224),\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "testdata = TestDataSet(data_dir, transform=test_transforms)\n",
    "test_loader = torch.utils.data.DataLoader(testdata, batch_size=100, shuffle=False, \n",
    "                               num_workers=20, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataSet(Dataset):\n",
    "    def __init__(self, open_dir, file_list):\n",
    "        self.desired_size = 1000\n",
    "        self.open_dir = open_dir\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ])\n",
    "        \n",
    "        self.all_paths = natsorted(file_list)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.open_dir, self.all_paths[idx])\n",
    "        #image = Image.open(img_path)\n",
    "        \n",
    "        #training images were resized to 1000x1000 initially\n",
    "        image = cv2.cvtColor(cv2.imread(self.open_dir+self.all_paths[idx], cv2.IMREAD_UNCHANGED), cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, (self.desired_size, self.desired_size), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "        image = Image.fromarray(image) #convert back to PIL for transforms\n",
    "        image = image.convert('RGB')\n",
    "        image = self.transform(image)\n",
    "\n",
    "        path = self.all_paths[idx]\n",
    "        return (image, path)\n",
    "    \n",
    "model = torch.load('../saved_models/bs128_e50_13classes_clean_vgg19').cuda()\n",
    "model.eval()\n",
    "campaign = 'MPACE'\n",
    "df = pd.read_pickle('../final_databases/no_mask/df_good_ice_'+campaign+'.pkl')\n",
    "data_dir = '../cpi_data/campaigns/'+campaign+'/single_imgs/'\n",
    "testdata = TestDataSet(data_dir, df['filename'])\n",
    "test_loader = torch.utils.data.DataLoader(testdata, batch_size=100, shuffle=False, \n",
    "                               num_workers=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "for batch_idx, (imgs, img_paths) in enumerate(test_loader):\n",
    "    #predictions = model_ft(imgs)\n",
    "    #preds = torch.max(predictions, 1).indices.tolist()   \n",
    "    for im in img_paths:\n",
    "        path = data_dir + im\n",
    "        probs, classes = predict2(path, model.to(device))\n",
    "        crystal_names = [params['class_names'][e] for e in classes]\n",
    "        view_classify(path, probs, crystal_names)\n",
    "        #save_image(data_dir, save_dir, crystal_names, im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "for batch_idx, (imgs, img_paths) in enumerate(test_loader):\n",
    "    for im in img_paths:\n",
    "        path = data_dir+im\n",
    "        img_og = Image.open(path)\n",
    "        img = img_og.convert('RGB')\n",
    "        img = process_image(img)\n",
    "\n",
    "        # Convert 2D image to 1D vector\n",
    "        img = np.expand_dims(img, 0)\n",
    "\n",
    "        img = torch.from_numpy(img)\n",
    "        prediction = model(img)\n",
    "        cpu_pred = prediction.cpu()\n",
    "        result = cpu_pred.data.numpy()\n",
    "        print(class_names[result.argmax()])\n",
    "        fig, ax = plt.subplots(figsize=(5, 5))\n",
    "        ax.imshow(img_og)\n",
    "        plt.show()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
