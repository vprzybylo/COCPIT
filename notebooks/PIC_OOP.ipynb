{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image as pil_img\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "import imutils\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import metrics\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_params = {'axes.labelsize': 'xx-large',\n",
    "         'axes.titlesize':'xx-large',\n",
    "         'xtick.labelsize':'x-large',\n",
    "         'ytick.labelsize':'xx-large'}\n",
    "plt.rcParams.update(plt_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Image():\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        \n",
    "    def open_image(self, open_dir):\n",
    "        \n",
    "        self.image_og = cv2.imread(open_dir+self.filename, cv2.IMREAD_UNCHANGED)\n",
    "        if self.image_og.shape[2] == 4 or  self.image_og.shape[2] == 3:\n",
    "            self.image_og =cv2.cvtColor(self.image_og, cv2.COLOR_BGR2RGB)\n",
    "        self.height, self.width, channel = self.image_og.shape\n",
    "    \n",
    "    def resize_padding(self, desired_size):\n",
    "        old_size = [self.width, self.height]\n",
    "        ratio = float(desired_size)/max(old_size)\n",
    "        new_size = tuple([int(x*ratio) for x in old_size])\n",
    "        resized = cv2.resize(self.image_og,new_size)\n",
    "\n",
    "        delta_w = desired_size - new_size[0]\n",
    "        delta_h = desired_size - new_size[1]\n",
    "        top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "        left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "\n",
    "        color = [0, 0, 0]\n",
    "        self.saveimg = cv2.copyMakeBorder(resized, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)\n",
    "    \n",
    "    def resize_stretch(self, desired_size):\n",
    "        self.saveimg = cv2.resize(self.image_og, (desired_size, desired_size), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "    def find_contours(self):\n",
    "        self.gray = cv2.cvtColor(self.image_og, cv2.COLOR_BGR2GRAY)\n",
    "        self.thresh = cv2.threshold(self.gray, 50, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "        \n",
    "        self.contours, hierarchy = cv2.findContours(self.thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        self.contours = sorted(self.contours, key=cv2.contourArea, reverse = True)\n",
    "        #plt.imshow(self.thresh)\n",
    "        #plt.show()\n",
    "        \n",
    "    def morph_contours(self):\n",
    "        kernel = np.ones((5,5), dtype='uint8')\n",
    "        image_close = cv2.morphologyEx(self.thresh, cv2.MORPH_CLOSE, kernel)\n",
    "        \n",
    "        self.contours, hierarchy = cv2.findContours(image_close, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)  \n",
    "        draw=cv2.drawContours(self.thresh, self.contours, -1, (0,0,255), 2)\n",
    "        draw = cv2.fillPoly(self.thresh, self.contours, color=(255,255,255))\n",
    "        #plt.imshow(draw)\n",
    "        #plt.show()\n",
    "\n",
    "        self.contours, hierarchy = cv2.findContours(draw, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        #self.contours = sorted(contours, key=cv2.contourArea, reverse = True)\n",
    "\n",
    "    def largest_contour(self):\n",
    "        return sorted(self.contours, key=cv2.contourArea, reverse = True)[0] \n",
    "    \n",
    "    def mask_background(self):\n",
    "        '''Keeps the background all white surrounding the largest conotour.\n",
    "        Places the largest contour on an array of all the same color'''\n",
    "        print(self.image_og.shape[:2])\n",
    "        mask = np.zeros(self.image_og.shape[:2], dtype=\"uint8\")\n",
    "        draw = cv2.drawContours(mask, [self.largest_contour()], 0, (255,255,255), -1)\n",
    "        self.im = cv2.bitwise_and(self.im, self.im, mask=mask)\n",
    "    \n",
    "    def edges(self):\n",
    "        min_threshold = 0.66 * np.mean(self.image_og)\n",
    "        max_threshold = 1.33 * np.mean(self.image_og)\n",
    "        edges = cv2.Canny(self.saveimg, min_threshold, max_threshold)\n",
    "        return edges\n",
    "        \n",
    "    def contrast(self):\n",
    "        return self.image_og.std()\n",
    "        \n",
    "    def laplacian(self):\n",
    "        self.laplacian = cv2.Laplacian(self.gray,cv2.CV_64F).var()\n",
    "        \n",
    "    def random_color(self):\n",
    "        rgbl=[255,0,0]\n",
    "        random.shuffle(rgbl)\n",
    "        return tuple(rgbl)\n",
    "\n",
    "    def cutoff(self):\n",
    "        #checking the percentage of the contour that touches the edge/border\n",
    "\n",
    "        locations = np.where(self.thresh != 0)\n",
    "        count = 0 #pixels touching border\n",
    "        for xl,yl in zip(locations[0], locations[1]):\n",
    "            if xl == 0 or yl == 0 or xl == self.height-1 or yl == self.width-1:\n",
    "                count+=1\n",
    "        cutoff_perc = (count/(2*self.height+2*self.width))*100\n",
    "        return cutoff_perc\n",
    "\n",
    "    def phi(self):\n",
    "        rect = cv2.minAreaRect(self.largest_contour()) #box ONLY around the largest contour \n",
    "        #get length and width of contour\n",
    "        x = rect[1][0]\n",
    "        y = rect[1][1]      \n",
    "        self.rect_length = max(x,y)\n",
    "        self.rect_width = min(x,y)\n",
    "        if self.rect_length != 0:\n",
    "            return self.rect_width/self.rect_length\n",
    "        else: \n",
    "            return 0\n",
    "        \n",
    "    def largest_contour_area(self):\n",
    "        return cv2.contourArea(self.largest_contour())  \n",
    "        \n",
    "    def area(self):\n",
    "        area = 0\n",
    "        for c in self.contours:\n",
    "            area+=cv2.contourArea(c)  \n",
    "            return area\n",
    "    \n",
    "    def perim(self):\n",
    "        if len(self.contours) == 1:\n",
    "            return cv2.arcLength(self.largest_contour(), False)\n",
    "        else: \n",
    "            return 0\n",
    "    \n",
    "    def hull_area(self):\n",
    "        hull = cv2.convexHull(self.largest_contour())      \n",
    "        return cv2.contourArea(hull)\n",
    "        \n",
    "    def perim_area(self):\n",
    "        return self.perim()/self.area()\n",
    "        \n",
    "    def convex_perim(self, closed_cnt):\n",
    "        hull = cv2.convexHull(self.largest_contour())\n",
    "        return cv2.arcLength(hull, closed_cnt)\n",
    "    \n",
    "    def equiv_d(self):\n",
    "        return np.sqrt(4*self.area()/np.pi)\n",
    "    \n",
    "    def circularity(self):\n",
    "        perim = self.perim()\n",
    "        hull_area = self.hull_area()\n",
    "        if perim != 0 and hull_area != 0 and self.area() != 0 and len(self.contours) == 1:\n",
    "            return (4.*np.pi*self.area())/(self.convex_perim(True)**2)\n",
    "            #return (4*np.pi*self.area)/(perim**2)\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def solidity(self):\n",
    "        if self.hull_area() != 0. and len(self.contours) == 1:\n",
    "            return float(self.area())/self.hull_area()\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def complexity(self):\n",
    "        if self.perim() != 0 and self.hull_area != 0 and self.area() != 0 and len(self.contours) == 1:\n",
    "            return 10*(0.1-(self.area()/(np.sqrt(self.area()/self.hull_area())*self.perim()**2)))\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def flip_imgs(self, save_dir):\n",
    "        plt.imsave(save_dir+self.filename,np.array(self.saveimg))\n",
    "        plt.imsave(save_dir+self.filename[:-4]+'_ud.png',np.flipud(self.saveimg))\n",
    "        plt.imsave(save_dir+self.filename[:-4]+'_lr.png',np.fliplr(self.saveimg))\n",
    "        plt.imsave(save_dir+self.filename[:-4]+'_ud_lr.png',np.flipud(np.fliplr(self.saveimg)))\n",
    "        \n",
    "    def rotate(self):\n",
    "        # loop over the rotation angles\n",
    "        for angle in np.arange(0, 360, 100):\n",
    "            self.saveimg = imutils.rotate_bound(self.saveimg, angle)\n",
    "            plt.imshow(self.saveimg)\n",
    "            plt.show()\n",
    "            \n",
    "    def show_image(self):\n",
    "        plt.imshow(self.image_og)\n",
    "        plt.show()\n",
    "        \n",
    "    def show_resized(self):\n",
    "        plt.imshow(self.saveimg)\n",
    "        plt.show()\n",
    "\n",
    "    def save_image(self, save_dir, flip = False):\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "        \n",
    "        if flip:\n",
    "            self.flip_imgs(save_dir)\n",
    "        else:\n",
    "            #save single image, no flipping:\n",
    "            cv2.imwrite(os.path.join(save_dir,str(self.filename)), np.array(self.saveimg))\n",
    "#         plt.imshow(self.saveimg)\n",
    "#         plt.show()\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    campaign = 'MPACE'\n",
    "    open_dirs = ['cpi_data/campaigns/'+campaign+'/single_imgs/', 'cpi_data/campaigns/'+campaign+'/bad_train/']\n",
    "    save_dir = 'cpi_data/hand_labeled_pristine/'\n",
    "    desired_size = 1000\n",
    "    category = 'none'\n",
    "    \n",
    "    #Independent Variable\n",
    "    good_bad = []\n",
    "    \n",
    "    #Dependent Variables\n",
    "    lapl = []\n",
    "    contours = []\n",
    "    edges = []\n",
    "    std = []\n",
    "    height = []\n",
    "    width = []\n",
    "    cnt_area = []\n",
    "    contrast = []\n",
    "    circularity = []\n",
    "    contrast = [] \n",
    "    solidity = []\n",
    "    complexity = []\n",
    "    equiv_d = []\n",
    "    convex_perim = []\n",
    "    perim_area = []\n",
    "    hull_area = []\n",
    "    perim = []\n",
    "    phi = []\n",
    "    cutoff = []\n",
    "\n",
    "    for direct in open_dirs:\n",
    "        \n",
    "        for filename in os.listdir(direct):\n",
    "            #want a good/bad index for every file\n",
    "            if direct == open_dirs[0]:\n",
    "                good_bad.append(0)\n",
    "            else:\n",
    "                good_bad.append(1)\n",
    "\n",
    "            image = Image(filename)\n",
    "            image.open_image(direct)\n",
    "            image.find_contours()\n",
    "            image.resize_stretch(desired_size)\n",
    "            #image.save_image(save_dir, flip=True)\n",
    "            if len(image.contours) > 1:\n",
    "                image.morph_contours()\n",
    "                \n",
    "            image.laplacian()\n",
    "            count_edge_px = np.count_nonzero(image.edges())\n",
    "            \n",
    "            lapl.append(image.laplacian)\n",
    "            contours.append(len(image.contours))\n",
    "            edges.append(count_edge_px)\n",
    "            contrast.append(image.contrast())\n",
    "            if count_edge_px > 0:\n",
    "                std.append(np.std(np.nonzero(image.edges())))\n",
    "            else:\n",
    "                std.append(0)\n",
    "            height.append(image.height)\n",
    "            width.append(image.width)\n",
    "\n",
    "            if len(image.contours)!=0 and image.area() > 0.00:\n",
    "                cnt_area.append(cv2.contourArea(image.largest_contour()))\n",
    "                solidity.append(image.solidity())\n",
    "                complexity.append(image.complexity())\n",
    "                equiv_d.append(image.equiv_d())\n",
    "                convex_perim.append(image.convex_perim(True))\n",
    "                perim_area.append(image.perim_area())\n",
    "                hull_area.append(image.hull_area())\n",
    "                perim.append(image.perim())\n",
    "                phi.append(image.phi())\n",
    "                circularity.append(image.circularity())\n",
    "                cutoff.append(image.cutoff())\n",
    "\n",
    "            else:\n",
    "                cnt_area.append(0)\n",
    "                solidity.append(0)\n",
    "                complexity.append(0)\n",
    "                equiv_d.append(0)\n",
    "                convex_perim.append(0)\n",
    "                perim_area.append(0)\n",
    "                hull_area.append(0)\n",
    "                perim.append(0)\n",
    "                phi.append(0)\n",
    "                circularity.append(0)\n",
    "                cutoff.append(0)\n",
    "                \n",
    "            ####FOR CATEGORIZATION AFTER GOOD IMAGES RETURNED###\n",
    "            if category == 'blank' and len(image.contours) == 0:\n",
    "                image.resize_stretch(desired_size)\n",
    "                image.show_resized()\n",
    "                #image.save_image(save_dir, flip=True)\n",
    "\n",
    "            if len(image.contours)!=0:\n",
    "                #cutoff_perc = image.cutoff()\n",
    "\n",
    "                laplacian = cv2.Laplacian(image.gray,cv2.CV_64F).var()\n",
    "\n",
    "                if category == 'spheres':\n",
    "                    if image.circularity() > 0.8 and image.solidity() > 0.8: \n",
    "                        #image.show_image()\n",
    "                        save_dir = 'cpi_data/campaigns/MPACE/spheres/'\n",
    "                        #image.save_image(save_dir, flip=False)\n",
    "                    else:\n",
    "                        #print(image.circularity(), image.solidity())\n",
    "                        save_dir = 'cpi_data/campaigns/MPACE/no_spheres/'\n",
    "                        #image.show_image()\n",
    "                        image.save_image(save_dir, flip=False)\n",
    "\n",
    "    #             if check_junk:\n",
    "    #                 #include blurry, blank, and fragments\n",
    "    #                 if laplacian > 1000 or len(image.contours) == 0 or \\\n",
    "    #                     (image.perim() !=-999 and image.area() != 0 and \\\n",
    "    #                     image.phi() < 0.5 and image.phi() !=-999 and \\\n",
    "    #                     cutoff_perc < 1 and 300 < laplacian < 700 and \\\n",
    "    #                     -999 < image.circularity() < 0.8 and \\\n",
    "    #                     (image.height < 60 and image.width < 60)):\n",
    "    #                     #print(laplacian)\n",
    "    #                     image.resize_stretch(desired_size)\n",
    "    #                     #image.show_resized()\n",
    "    #                 #if laplacian < 1000:\n",
    "\n",
    "\n",
    "                if category == 'blurry':\n",
    "                    if laplacian > 5000:    \n",
    "                        image.resize_stretch(desired_size)\n",
    "                        #image.save_image(save_dir, flip=True)\n",
    "                        #image.show_resized()\n",
    "\n",
    "                if category== 'fragment':\n",
    "                    if image.perim() !=-999 and image.area() != 0 and \\\n",
    "                        image.phi() < 0.5 and image.phi() !=-999 and \\\n",
    "                        cutoff_perc < 1 and 300 < laplacian < 700 and \\\n",
    "                        -999 < image.circularity() < 0.8 and \\\n",
    "                        (image.height < 60 and image.width < 60):  \n",
    "                        image.resize_stretch(desired_size) \n",
    "                        image.show_resized()\n",
    "\n",
    "                if category == 'columns':\n",
    "                    #print(image.phi())\n",
    "                    #if len gt 1.9*wid and perim/area < 1.3*(2*(len+wid)/(len*wid))\n",
    "                    if image.perim() !=-999 and image.area() != 0 and \\\n",
    "                        image.phi() < 0.4 and image.phi() !=-999 and \\\n",
    "                        cutoff_perc < 2. and 300 < laplacian < 700 and \\\n",
    "                        image.solidity() > 0.9 and image.rect_length > 40 and image.rect_width > 40:  \n",
    "                        image.resize_stretch(desired_size) \n",
    "                        #image.save_image(save_dir, flip=True)\n",
    "\n",
    "                if category == 'junk':\n",
    "                    image.phi()\n",
    "                    image.resize_stretch(desired_size)\n",
    "                    if (image.length < 20 or image.width < 20) and image.phi() > 0.3 and \\\n",
    "                        image.phi() < 0.8 and \\\n",
    "                        cutoff_perc < 20 and laplacian < 1000 and laplacian > 600 and \\\n",
    "                        image.area() > 20.0 and image.circularity() < 0.7:\n",
    "                        image.show_resized()\n",
    "\n",
    "                if category == 'rimed_columns':\n",
    "                    if image.perim() != -999 and image.solidity() > 0.3 and image.phi() < 0.5 and \\\n",
    "                        laplacian < 700 and image.perim_area() < .1:\n",
    "                        image.resize_stretch(desired_size)\n",
    "                        print(image.solidity(), image.complexity(), image.phi(), image.perim(), image.perim_area())\n",
    "                        image.show_resized()\n",
    "\n",
    "    #set up dictionary for good and bad data metrics\n",
    "    dicts = {}\n",
    "    keys = ['good_bad', 'lapl', 'contours', 'edges', 'std', 'height', 'width', 'cnt_area', \\\n",
    "           'contrast', 'circularity', 'solidity','complexity','equiv_d','convex_perim',\\\n",
    "           'perim_area', 'hull_area', 'perim', 'phi', 'cutoff']\n",
    "    values =  [good_bad, lapl, contours, edges, std, height, width, cnt_area, \\\n",
    "           contrast, circularity, solidity, complexity, equiv_d, convex_perim,\\\n",
    "           perim_area, hull_area, perim, phi, cutoff]\n",
    "    for key, val in zip(keys, values):\n",
    "        dicts[key] = val\n",
    "    #dicts = {'good_bad': good_bad, 'lapl': lapl, 'contours':contours, 'edges':edges, 'std':std, 'height':height, \\\n",
    "    #        'width':width, 'cnt_area':cnt_area, }\n",
    "    \n",
    "    df = pd.DataFrame(dicts)\n",
    "    return df\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    %time df = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for row in df['width']:\n",
    "    if row == 1000:\n",
    "        count+=1 \n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df.drop(df[(df['height'] == 1000) & (df['width'] == 1000)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['lapl', 'contours', 'edges', 'std', 'height', 'width', 'cnt_area', \\\n",
    "           'contrast', 'circularity', 'solidity','complexity','equiv_d','convex_perim',\\\n",
    "           'perim_area','hull_area','perim','phi', 'cutoff']\n",
    "# predictors = ['lapl', 'contours', 'edges', 'std', 'width', 'cnt_area', 'contrast', 'hull_area', 'solidity', 'phi',\n",
    "#              'perim_area', 'cutoff', 'circularity', 'convex_perim', 'complexity']\n",
    "\n",
    "#X = df.drop('good_bad', 1)\n",
    "X = df_new[predictors]\n",
    "y = df_new['good_bad']\n",
    "\n",
    "logit_model=sm.Logit(y, X, missing='drop')\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(19, 15))\n",
    "plt.matshow(df.corr(), fignum=f.number)\n",
    "plt.xticks(range(df.shape[1]), df.columns, fontsize=14, rotation=45)\n",
    "plt.yticks(range(df.shape[1]), df.columns, fontsize=14)\n",
    "cb = plt.colorbar()\n",
    "cb.ax.tick_params(labelsize=14)\n",
    "plt.title('Correlation Matrix', fontsize=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=df['edges'], y=df['good_bad'], y_jitter=0.03, logistic = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=df['width'], y=df['good_bad'], y_jitter=0.03, logistic = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=df['cnt_area'], y=df['good_bad'], y_jitter=0.03, logistic = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=df['solidity'], y=df['good_bad'], y_jitter=0.03, logistic = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=df['contrast'], y=df['good_bad'], y_jitter=0.03, logistic = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=df['perim'], y=df['good_bad'], y_jitter=0.03, logistic = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca = df_new[df_new['contours'] == 1].drop('good_bad', 1)\n",
    "y_pca = df_new[df_new['contours'] == 1]['good_bad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y_pca, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_variance = pca.explained_variance_ratio_\n",
    "explained_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(explained_variance)), explained_variance, marker='o')\n",
    "plt.xlabel(\"Principal Component\")\n",
    "plt.ylabel('Variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(7, 7))\n",
    "ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=90, azim=10)\n",
    "ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print('Accuracy: %.2f' %(accuracy_score(y_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(kernel='linear')\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print('Accuracy: %.2f' %(accuracy_score(y_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make new prediction based on logit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "campaign = '2004_Midcix'\n",
    "open_dir = 'cpi_data/campaigns/'+campaign+'/single_imgs/'\n",
    "save_dir_good = 'cpi_data/campaigns/'+campaign+'/good/'\n",
    "save_dir_bad = 'cpi_data/campaigns/'+campaign+'/bad/'\n",
    "desired_size = 1000\n",
    "\n",
    "bad = 0\n",
    "good = 0\n",
    "for filename in os.listdir(open_dir):\n",
    "    image = Image(filename)\n",
    "    image.open_image(open_dir)\n",
    "    image.find_contours()\n",
    "    image.resize_stretch(desired_size)\n",
    "    image.laplacian()\n",
    "    if len(image.contours) > 1:\n",
    "        image.morph_contours()\n",
    "    \n",
    "    lapl = image.laplacian\n",
    "    contours = len(image.contours)\n",
    "    edges = np.count_nonzero(image.edges())       \n",
    "    if edges > 0:\n",
    "        std=np.std(np.nonzero(image.edges()))\n",
    "    else:\n",
    "        std=0\n",
    "    height = image.height\n",
    "    width = image.width\n",
    "    contrast = image.contrast()\n",
    "\n",
    "    if len(image.contours)!= 0 and image.area() > 0.00:\n",
    "        \n",
    "        cnt_area = cv2.contourArea(image.largest_contour())\n",
    "        solidity=image.solidity()\n",
    "        complexity=image.complexity()\n",
    "        equiv_d=image.equiv_d()\n",
    "        convex_perim=image.convex_perim(True)\n",
    "        perim_area=image.perim_area()\n",
    "        hull_area=image.hull_area()\n",
    "        perim=image.perim()\n",
    "        phi=image.phi()\n",
    "        circularity=image.circularity()\n",
    "        cutoff = image.cutoff()\n",
    "    else:\n",
    "        cnt_area=0\n",
    "        solidity=0\n",
    "        complexity=0\n",
    "        equiv_d=0\n",
    "        convex_perim=0\n",
    "        perim_area=0\n",
    "        hull_area=0\n",
    "        perim=0\n",
    "        phi=0\n",
    "        circularity=0\n",
    "        cutoff = 0\n",
    "\n",
    "    dicts = {}\n",
    "    keys = ['lapl', 'contours', 'edges', 'std', 'height', 'width', 'cnt_area', \\\n",
    "           'contrast', 'circularity', 'solidity','complexity','equiv_d','convex_perim',\\\n",
    "           'perim_area', 'hull_area', 'perim', 'phi', 'cutoff']\n",
    "    values =  [lapl, contours, edges, std, height, width, cnt_area, \\\n",
    "           contrast, circularity, solidity, complexity, equiv_d, convex_perim,\\\n",
    "           perim_area, hull_area, perim, phi, cutoff]\n",
    "\n",
    "    for key, val in zip(keys, values):\n",
    "        dicts[key] = val\n",
    "    df = pd.DataFrame(dicts, index=[0])\n",
    "    \n",
    "    #Regression model prediction\n",
    "    pred = result.predict(df)\n",
    "    \n",
    "    df = pca.transform(df)\n",
    "    #SVC prediction\n",
    "    #pred = clf.predict(df)\n",
    "    \n",
    "    #PCA prediction\n",
    "    #pred = classifier.predict(df)\n",
    "    \n",
    "    #print(pred[0])\n",
    "    if pred[0] < 0.5:\n",
    "        if len(image.contours) != 0:\n",
    "            print(image.cutoff())\n",
    "            print(\"GOOD\")\n",
    "            image.show_image()\n",
    "            plt.show()\n",
    "            #image.save_image(save_dir_good)\n",
    "            good += 1\n",
    "    else:\n",
    "#         print(\"BAD\")\n",
    "#         image.show_image()\n",
    "#         plt.show()\n",
    "         #image.save_image(save_dir_bad)\n",
    "        bad += 1\n",
    "\n",
    "print((good/(good+bad))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def reject_outliers(data):\n",
    "    m = 4\n",
    "    u = np.nanmean(data)\n",
    "    s = np.std(data)\n",
    "    filtered = [e for e in data if (u - m * s < e < u + m * s)]\n",
    "    return filtered\n",
    "\n",
    "std_filt = reject_outliers(std)\n",
    "contours_filt=reject_outliers(contours)\n",
    "edges_filt = reject_outliers(edges)\n",
    "lapl_arr_filt = reject_outliers(lapl_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1) \n",
    "ax.hist(lapl_arr_filt, bins = 10, density=True )\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1) \n",
    "ax.hist(std_filt)\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1) \n",
    "ax.hist(contours_filt, bins = 70)\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1) \n",
    "ax.hist(edges_filt, bins = 70, density=True)\n",
    "ax.set_xlim(0,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(filename):  \n",
    "    save_dir = '../../cpi_data/OLYMPEX/new_labels3/aggs/'\n",
    "    desired_size = 1000\n",
    "    image = Image(filename)\n",
    "    \n",
    "    image.open_image(open_dir)\n",
    "    image.mask_background()\n",
    "    #image.find_contours()\n",
    "    #laplacian = cv2.Laplacian(image.gray,cv2.CV_64F).var()\n",
    "  \n",
    "    #if len(image.contours)!=0 and laplacian > 4000:\n",
    "\n",
    "    #image.resize(desired_size) \n",
    "    #image.save_image(save_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Image' object has no attribute 'contours'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-e88bee391db2>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_background\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m#image.find_contours()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#laplacian = cv2.Laplacian(image.gray,cv2.CV_64F).var()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-deff2cb3753f>\u001b[0m in \u001b[0;36mmask_background\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_og\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_og\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"uint8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mdraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrawContours\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlargest_contour\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbitwise_and\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-deff2cb3753f>\u001b[0m in \u001b[0;36mlargest_contour\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlargest_contour\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontours\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontourArea\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmask_background\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Image' object has no attribute 'contours'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if __name__ == '__main__':\n",
    "    open_dir = '../cpi_data/campaigns/OLYMPEX/single_imgs1/'\n",
    "    filenames = os.listdir(open_dir)\n",
    "    main(filenames[40])\n",
    "    #print(multiprocessing.cpu_count())  #80\n",
    "    #with Pool(multiprocessing.cpu_count()) as p:\n",
    "    #    p.map(main, filenames)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spheres blurriness values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lapl_arr = np.array(lapl_arr)\n",
    "lapl_arr[lapl_arr < 2.] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#second mode starts at 175\n",
    "fig, ax = plt.subplots( nrows=1, ncols=1 ) \n",
    "ax.hist(lapl_arr, bins = 70)\n",
    "#ax.set_xlim(100,300)\n",
    "#fig.savefig('sphere_lapl_hist.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read csv's\n",
    "import csv\n",
    "\n",
    "def readFile(filename):\n",
    "    files = []\n",
    "    areas = []\n",
    "    perims = []\n",
    "    lengths = []\n",
    "    widths = []\n",
    "    Cs = []\n",
    "    solidities = []\n",
    "    cplxs = []\n",
    "    with open(filename) as csvDataFile:\n",
    "        csvReader = csv.reader(csvDataFile)\n",
    "        next(csvReader, None)  # skip the headers\n",
    "        for row in csvReader:\n",
    "            \n",
    "            files.append(row[0])\n",
    "            areas.append(float(row[1])) \n",
    "            perims.append(float(row[2])) \n",
    "            lengths.append(float(row[3]))\n",
    "            widths.append(float(row[4]))\n",
    "            Cs.append(float(row[5]))\n",
    "            solidities.append(float(row[6]))\n",
    "            cplxs.append(float(row[7]))\n",
    "\n",
    "    return files, areas, perims, lengths, widths, Cs, solidities, cplxs\n",
    "\n",
    "\n",
    "files, areas, perims, lengths, widths, Cs, solidities, cplxs = readFile('pristine_columns_out_file.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
