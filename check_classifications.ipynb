{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cocpit\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from natsort import natsorted\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_params = {'axes.labelsize': 'xx-large',\n",
    "         'axes.titlesize':'xx-large',\n",
    "         'xtick.labelsize':'x-large',\n",
    "         'ytick.labelsize':'xx-large'}\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "plt.rcParams.update(plt_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check classifications from df or db file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "campaign='MACPEX'\n",
    "df = pd.read_csv('final_databases_v2/no_mask/'+campaign+'.csv')\n",
    "desired_size = 1000\n",
    "for file, class_ in zip(df['filename'], df['classification']):\n",
    "    #print(file)\n",
    "    image = cocpit.pic.Image('cpi_data/campaigns/'+campaign+'/single_imgs/', file)\n",
    "    image.resize_stretch(desired_size)\n",
    "    print(class_)\n",
    "    if class_ != 'blurry':\n",
    "        plt.imshow(image.image_og)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check classifications from specific model and validation dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['aggs','blank','blurry','budding',\n",
    "              'bullets','columns','compact irregulars',\n",
    "              'fragments','needles','plates','rimed aggs',\n",
    "              'rimed columns','spheres']\n",
    "model = torch.load('/data/data/saved_models/no_mask/e20_bs128_k0_1models_vgg19').cuda()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "val_data = torch.load('/data/data/saved_models/no_mask/val_data_vgg19_e20_b128.pt')\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_data,\n",
    "                                         batch_size=128,\n",
    "                                         shuffle=True,\n",
    "                                         num_workers=20,\n",
    "                                         pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "for batch_idx, ((imgs, labels, paths), index) in enumerate(val_loader):\n",
    "    #predictions = model_ft(imgs)\n",
    "    #preds = torch.max(predictions, 1).indices.tolist()    \n",
    "    for path, label in zip(paths, labels):\n",
    "        probs, classes = cocpit.check_classifications.predict(path, device, model)  \n",
    "        label = label.numpy()\n",
    "        crystal_names = [class_names[e] for e in classes]\n",
    "        if crystal_names[0] != class_names[label]:\n",
    "            print('labeled as: ', class_names[label])\n",
    "            cocpit.check_classifications.view_classify(path, probs, crystal_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VGG NO OVERFIT, 10 epochs\n",
    "class_names = ['aggs','blank','blurry','budding',\n",
    "              'bullets','columns','compact irregulars',\n",
    "              'fragments','needles','plates','rimed aggs',\n",
    "              'rimed columns','spheres']\n",
    "model = torch.load('/data/data/saved_models/no_mask/e10_bs128_k0_1models_vgg19').cuda()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "val_data = torch.load('/data/data/saved_models/no_mask/val_data_no_overfit.pt')\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_data,\n",
    "                                         batch_size=128,\n",
    "                                         shuffle=True,\n",
    "                                         num_workers=20,\n",
    "                                         pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "for batch_idx, ((imgs, labels, paths), index) in enumerate(val_loader):\n",
    "    #predictions = model_ft(imgs)\n",
    "    #preds = torch.max(predictions, 1).indices.tolist()    \n",
    "    for path in paths:\n",
    "        probs, classes = cocpit.check_classifications.predict(path, device, model)  \n",
    "        crystal_names = [class_names[e] for e in classes]\n",
    "        cocpit.check_classifications.view_classify(path, probs, crystal_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on new data - Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from raw image folder (i.e., single_imgs)\n",
    "class TestDataSet(Dataset):\n",
    "    def __init__(self, main_dir, transform):\n",
    "        self.main_dir = main_dir\n",
    "        self.transform = transform\n",
    "        all_imgs = os.listdir(main_dir)\n",
    "        self.total_imgs = natsorted(all_imgs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.total_imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_loc = os.path.join(self.main_dir, self.total_imgs[idx])\n",
    "        image = Image.open(img_loc)\n",
    "        #print(image)\n",
    "        #image =cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        tensor_image = self.transform(image)\n",
    "        path = self.total_imgs[idx]\n",
    "        return tensor_image, path\n",
    "\n",
    "model = torch.load('/data/data/saved_models/no_mask/e50_bs128_k0_8models_vgg19').cuda()\n",
    "model.eval()\n",
    "campaign = 'ARM'\n",
    "data_dir = '/data/data/cpi_data/campaigns/'+campaign+'/single_imgs/'\n",
    "#save_dir = 'cpi_data/campaigns/'+campaign+'/'\n",
    "\n",
    "#apply same transforms\n",
    "test_transforms = transforms.Compose([transforms.Resize(224),\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                             [0.229, 0.224, 0.225])])\n",
    "\n",
    "testdata = TestDataSet(data_dir, transform=test_transforms)\n",
    "test_loader = torch.utils.data.DataLoader(testdata, batch_size=100, shuffle=False, \n",
    "                               num_workers=20, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "for batch_idx, (imgs, labels, paths) in enumerate(val_loader):\n",
    "    #predictions = model_ft(imgs)\n",
    "    #preds = torch.max(predictions, 1).indices.tolist()    \n",
    "    for path in paths:\n",
    "        probs, classes = cocpit.check_classifications.predict(path, device, model)  \n",
    "        crystal_names = [class_names[e] for e in classes]\n",
    "        cocpit.check_classifications.view_classify(path, probs, crystal_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "for batch_idx, (imgs, img_paths) in enumerate(test_loader):\n",
    "    for im in img_paths:\n",
    "        path = data_dir+im\n",
    "        img_og = Image.open(path)\n",
    "        img = img_og.convert('RGB')\n",
    "        img = cocpit.check_classifications.process_image(img)\n",
    "\n",
    "        # Convert 2D image to 1D vector\n",
    "        img = np.expand_dims(img, 0)\n",
    "\n",
    "        img = torch.from_numpy(img)\n",
    "        prediction = model(img)\n",
    "        cpu_pred = prediction.cpu()\n",
    "        result = cpu_pred.data.numpy()\n",
    "        print(class_names[result.argmax()])\n",
    "        fig, ax = plt.subplots(figsize=(5, 5))\n",
    "        ax.imshow(img_og)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
